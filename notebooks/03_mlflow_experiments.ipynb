{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. MLflow Experiment Tracking\n",
    "\n",
    "**MLOps Assignment - BITS Pilani (S1-25_AIMLCZG523)**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives (5 marks)\n",
    "1. **Integrate MLflow** for experiment tracking\n",
    "2. **Log Parameters** - Hyperparameters for each model\n",
    "3. **Log Metrics** - Accuracy, Precision, Recall, F1, ROC-AUC\n",
    "4. **Log Artifacts** - Confusion matrix, ROC curves, models\n",
    "5. **Compare Experiments** - Analyze multiple runs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:46.111197Z",
     "iopub.status.busy": "2025-12-30T23:17:46.111079Z",
     "iopub.status.idle": "2025-12-30T23:17:47.921854Z",
     "shell.execute_reply": "2025-12-30T23:17:47.921420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skshahrukh.saba/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded successfully!\n",
      "MLflow version: 3.1.4\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, roc_curve\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:47.923579Z",
     "iopub.status.busy": "2025-12-30T23:17:47.923386Z",
     "iopub.status.idle": "2025-12-30T23:17:47.935371Z",
     "shell.execute_reply": "2025-12-30T23:17:47.935015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 03:17:47 INFO mlflow.tracking.fluent: Experiment with name 'heart_disease_classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/skshahrukh.saba/Downloads/MLOps_assignment\n",
      "============================================================\n",
      "MLFLOW TRACKING SETUP\n",
      "============================================================\n",
      "Tracking URI: file:///Users/skshahrukh.saba/Downloads/MLOps_assignment/mlruns\n",
      "Experiment: heart_disease_classification\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup MLflow tracking URI (local file-based tracking)\n",
    "# Force PROJECT_ROOT to MLOps_assignment directory\n",
    "PROJECT_ROOT = '/Users/skshahrukh.saba/Downloads/MLOps_assignment'\n",
    "\n",
    "# Change to project root for correct relative paths\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Setup MLflow with explicit absolute path\n",
    "mlflow_dir = os.path.join(PROJECT_ROOT, 'mlruns')\n",
    "os.makedirs(mlflow_dir, exist_ok=True)\n",
    "mlflow.set_tracking_uri(f\"file://{mlflow_dir}\")\n",
    "\n",
    "# Create experiment\n",
    "EXPERIMENT_NAME = \"heart_disease_classification\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# Disable autologging to avoid conflicts in notebook\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MLFLOW TRACKING SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Tracking URI: file://{mlflow_dir}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:47.936876Z",
     "iopub.status.busy": "2025-12-30T23:17:47.936774Z",
     "iopub.status.idle": "2025-12-30T23:17:47.945752Z",
     "shell.execute_reply": "2025-12-30T23:17:47.945434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /Users/skshahrukh.saba/Downloads/MLOps_assignment/data/processed/heart_disease_clean.csv\n",
      "Training samples: 237\n",
      "Test samples: 60\n"
     ]
    }
   ],
   "source": [
    "# Load data (using absolute path based on PROJECT_ROOT)\n",
    "data_path = os.path.join(PROJECT_ROOT, 'data/processed/heart_disease_clean.csv')\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define features\n",
    "NUMERICAL_FEATURES = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "CATEGORICAL_FEATURES = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), NUMERICAL_FEATURES),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), CATEGORICAL_FEATURES)\n",
    "])\n",
    "\n",
    "# Create screenshots directory\n",
    "SCREENSHOTS_DIR = os.path.join(PROJECT_ROOT, 'screenshots')\n",
    "os.makedirs(SCREENSHOTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment 1: Logistic Regression with MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:47.947205Z",
     "iopub.status.busy": "2025-12-30T23:17:47.947110Z",
     "iopub.status.idle": "2025-12-30T23:17:50.282024Z",
     "shell.execute_reply": "2025-12-30T23:17:50.281637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parameters logged:\n",
      "   C: 1.0\n",
      "   penalty: l2\n",
      "   solver: lbfgs\n",
      "   max_iter: 1000\n",
      "\n",
      "âœ… Metrics logged:\n",
      "   accuracy: 0.8000\n",
      "   precision: 0.8333\n",
      "   recall: 0.7143\n",
      "   f1_score: 0.7692\n",
      "   roc_auc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 03:17:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Artifact logged: lr_confusion_matrix.png\n",
      "âœ… Artifact logged: lr_roc_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/31 03:17:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model logged\n",
      "\n",
      "ğŸ“ Run ID: 90e876afda0a4569af3720ca1ab789af\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 1: Logistic Regression\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Experiment\") as run:\n",
    "    \n",
    "    # Log tags\n",
    "    mlflow.set_tags({\n",
    "        \"model_type\": \"LogisticRegression\",\n",
    "        \"dataset\": \"heart_disease_uci\",\n",
    "        \"phase\": \"experiment\"\n",
    "    })\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'C': 1.0,\n",
    "        'penalty': 'l2',\n",
    "        'solver': 'lbfgs',\n",
    "        'max_iter': 1000\n",
    "    }\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    print(\"âœ… Parameters logged:\")\n",
    "    for k, v in params.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    lr_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(**params, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    lr_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = lr_pipeline.predict(X_test)\n",
    "    y_prob = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(\"\\nâœ… Metrics logged:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"   {k}: {v:.4f}\")\n",
    "    \n",
    "    # Create confusion matrix plot (save locally then log)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title('Confusion Matrix - Logistic Regression')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    lr_cm_path = os.path.join(SCREENSHOTS_DIR, '03_lr_confusion_matrix.png')\n",
    "    fig.savefig(lr_cm_path, dpi=150)\n",
    "    mlflow.log_artifact(lr_cm_path)\n",
    "    plt.close()\n",
    "    print(\"\\nâœ… Artifact logged: lr_confusion_matrix.png\")\n",
    "    \n",
    "    # Create ROC curve (save locally then log)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve - Logistic Regression')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    lr_roc_path = os.path.join(SCREENSHOTS_DIR, '03_lr_roc_curve.png')\n",
    "    fig.savefig(lr_roc_path, dpi=150)\n",
    "    mlflow.log_artifact(lr_roc_path)\n",
    "    plt.close()\n",
    "    print(\"âœ… Artifact logged: lr_roc_curve.png\")\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lr_pipeline, \"model\")\n",
    "    print(\"âœ… Model logged\")\n",
    "    \n",
    "    lr_run_id = run.info.run_id\n",
    "    print(f\"\\nğŸ“ Run ID: {lr_run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 2: Random Forest with MLflow Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:50.283758Z",
     "iopub.status.busy": "2025-12-30T23:17:50.283634Z",
     "iopub.status.idle": "2025-12-30T23:17:52.470337Z",
     "shell.execute_reply": "2025-12-30T23:17:52.469892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parameters logged:\n",
      "   n_estimators: 200\n",
      "   max_depth: 10\n",
      "   min_samples_split: 5\n",
      "   min_samples_leaf: 1\n",
      "\n",
      "âœ… Metrics logged:\n",
      "   accuracy: 0.8167\n",
      "   precision: 0.8148\n",
      "   recall: 0.7857\n",
      "   f1_score: 0.8000\n",
      "   roc_auc: 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 03:17:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Artifact logged: rf_confusion_matrix.png\n",
      "âœ… Artifact logged: rf_roc_curve.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/31 03:17:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model logged\n",
      "\n",
      "ğŸ“ Run ID: 9ab9957e19d540dd8a216b65c24250b4\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 2: Random Forest\n",
    "with mlflow.start_run(run_name=\"RandomForest_Experiment\") as run:\n",
    "    \n",
    "    # Log tags\n",
    "    mlflow.set_tags({\n",
    "        \"model_type\": \"RandomForest\",\n",
    "        \"dataset\": \"heart_disease_uci\",\n",
    "        \"phase\": \"experiment\"\n",
    "    })\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': 200,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 1\n",
    "    }\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    print(\"âœ… Parameters logged:\")\n",
    "    for k, v in params.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(**params, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train model\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "    y_prob = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(\"\\nâœ… Metrics logged:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"   {k}: {v:.4f}\")\n",
    "    \n",
    "    # Create confusion matrix (save locally then log)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=ax)\n",
    "    ax.set_title('Confusion Matrix - Random Forest')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    rf_cm_path = os.path.join(SCREENSHOTS_DIR, '03_rf_confusion_matrix.png')\n",
    "    fig.savefig(rf_cm_path, dpi=150)\n",
    "    mlflow.log_artifact(rf_cm_path)\n",
    "    plt.close()\n",
    "    print(\"\\nâœ… Artifact logged: rf_confusion_matrix.png\")\n",
    "    \n",
    "    # Create ROC curve (save locally then log)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    ax.plot(fpr, tpr, 'g-', linewidth=2, label=f'ROC (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve - Random Forest')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    rf_roc_path = os.path.join(SCREENSHOTS_DIR, '03_rf_roc_curve.png')\n",
    "    fig.savefig(rf_roc_path, dpi=150)\n",
    "    mlflow.log_artifact(rf_roc_path)\n",
    "    plt.close()\n",
    "    print(\"âœ… Artifact logged: rf_roc_curve.png\")\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf_pipeline, \"model\")\n",
    "    print(\"âœ… Model logged\")\n",
    "    \n",
    "    rf_run_id = run.info.run_id\n",
    "    print(f\"\\nğŸ“ Run ID: {rf_run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLflow Tracking Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:52.471956Z",
     "iopub.status.busy": "2025-12-30T23:17:52.471793Z",
     "iopub.status.idle": "2025-12-30T23:17:52.475147Z",
     "shell.execute_reply": "2025-12-30T23:17:52.474847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "               MLFLOW EXPERIMENT TRACKING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                    WHAT WE LOGGED TO MLFLOW                         â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  âœ… PARAMETERS:                                                      â”‚\n",
      "â”‚     - Model hyperparameters (C, penalty, n_estimators, etc.)        â”‚\n",
      "â”‚     - Training configuration                                         â”‚\n",
      "â”‚                                                                      â”‚\n",
      "â”‚  âœ… METRICS:                                                         â”‚\n",
      "â”‚     - Accuracy, Precision, Recall, F1-Score, ROC-AUC                â”‚\n",
      "â”‚     - Logged for each experiment run                                 â”‚\n",
      "â”‚                                                                      â”‚\n",
      "â”‚  âœ… ARTIFACTS:                                                       â”‚\n",
      "â”‚     - Confusion matrix plots (PNG)                                   â”‚\n",
      "â”‚     - ROC curve plots (PNG)                                          â”‚\n",
      "â”‚     - Trained model files (pickle)                                   â”‚\n",
      "â”‚                                                                      â”‚\n",
      "â”‚  âœ… TAGS:                                                            â”‚\n",
      "â”‚     - model_type, dataset, phase                                     â”‚\n",
      "â”‚                                                                      â”‚\n",
      "â”‚  ğŸ“ MLflow Tracking Directory: mlruns/                               â”‚\n",
      "â”‚  ğŸŒ To view UI: mlflow ui --backend-store-uri ./mlruns              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "âœ… Experiment Tracking with MLflow COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY\n",
    "print(\"=\" * 70)\n",
    "print(\"               MLFLOW EXPERIMENT TRACKING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    WHAT WE LOGGED TO MLFLOW                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  âœ… PARAMETERS:                                                      â”‚\n",
    "â”‚     - Model hyperparameters (C, penalty, n_estimators, etc.)        â”‚\n",
    "â”‚     - Training configuration                                         â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  âœ… METRICS:                                                         â”‚\n",
    "â”‚     - Accuracy, Precision, Recall, F1-Score, ROC-AUC                â”‚\n",
    "â”‚     - Logged for each experiment run                                 â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  âœ… ARTIFACTS:                                                       â”‚\n",
    "â”‚     - Confusion matrix plots (PNG)                                   â”‚\n",
    "â”‚     - ROC curve plots (PNG)                                          â”‚\n",
    "â”‚     - Trained model files (pickle)                                   â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  âœ… TAGS:                                                            â”‚\n",
    "â”‚     - model_type, dataset, phase                                     â”‚\n",
    "â”‚                                                                      â”‚\n",
    "â”‚  ğŸ“ MLflow Tracking Directory: mlruns/                               â”‚\n",
    "â”‚  ğŸŒ To view UI: mlflow ui --backend-store-uri ./mlruns              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "print(\"âœ… Experiment Tracking with MLflow COMPLETE!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T23:17:52.476329Z",
     "iopub.status.busy": "2025-12-30T23:17:52.476234Z",
     "iopub.status.idle": "2025-12-30T23:17:52.489013Z",
     "shell.execute_reply": "2025-12-30T23:17:52.488678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                    MLFLOW EXPERIMENT RUNS\n",
      "======================================================================\n",
      "                     Run Name         Model Type  Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "LogisticRegression_Experiment LogisticRegression  0.800000   0.833333 0.714286  0.769231 0.928571\n",
      "      RandomForest_Experiment       RandomForest  0.816667   0.814815 0.785714  0.800000 0.915179\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Query all runs from the experiment\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        order_by=[\"metrics.roc_auc DESC\"]\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"                    MLFLOW EXPERIMENT RUNS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    comparison_data = []\n",
    "    for run in runs[:10]:  # Show top 10 runs\n",
    "        run_data = {\n",
    "            'Run Name': run.data.tags.get('mlflow.runName', 'N/A'),\n",
    "            'Model Type': run.data.tags.get('model_type', 'N/A'),\n",
    "            'Accuracy': run.data.metrics.get('accuracy', 0),\n",
    "            'Precision': run.data.metrics.get('precision', 0),\n",
    "            'Recall': run.data.metrics.get('recall', 0),\n",
    "            'F1-Score': run.data.metrics.get('f1_score', 0),\n",
    "            'ROC-AUC': run.data.metrics.get('roc_auc', 0),\n",
    "        }\n",
    "        comparison_data.append(run_data)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"No experiment found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
